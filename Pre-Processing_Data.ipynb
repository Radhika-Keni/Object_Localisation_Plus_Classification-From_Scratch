{"cells":[{"cell_type":"markdown","metadata":{"id":"1qqVfSfq_5sc"},"source":["### Summary of Notebook\n","- In this notebook , we will pre-process the input data to make it compatible for model building\n","- First do a Train-Test split and create 2 subsets (70:30 split)\n","- We will convert all images to tensors for both subsets\n","- Resize all the images to one pre-defined size, convert bounding boxes accordingly\n","- Visualize data and see that everything looks good\n","- At the end of this program , data will be  ready for model building"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3uiq91mZZlql"},"outputs":[],"source":["# Import Genereal libs  libraries\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import sys\n","import numpy as np\n","import seaborn as sns\n","import statistics as stats\n","sns.set(color_codes=True)\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","#Last import allows multiple outputs from one cell\n","import warnings\n","# Initialize the random number generator\n","import pickle\n","import random\n","random.seed(101)\n","# Import project specific libs\n","import tarfile\n","import os\n","import matplotlib.image as img\n","import cv2\n","import matplotlib.patches as patches\n","import tensorflow as tf\n","import pickle\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpNmHdWMujxD","executionInfo":{"status":"ok","timestamp":1675888707045,"user_tz":-330,"elapsed":25,"user":{"displayName":"Radhika Keni","userId":"06333197448618588360"}},"outputId":"947568c3-0268-4a25-a30f-60b1e399687e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v35Ofle0Z7Eu"},"outputs":[],"source":["# Useful Configuration/Setting\n","\n","# suppress display of warnings\n","warnings.filterwarnings('ignore')\n","\n","# display all dataframe columns\n","pd.options.display.max_columns = None\n","\n","# to set the limit to 3 decimals\n","pd.options.display.float_format = '{:.7f}'.format\n","\n","# display all dataframe rows\n","pd.options.display.max_rows = None\n","\n","#Setting to shows all entries in array displayed\n","np.set_printoptions(threshold=sys.maxsize)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3795,"status":"ok","timestamp":1675888748378,"user":{"displayName":"Radhika Keni","userId":"06333197448618588360"},"user_tz":-330},"id":"IPOzkfY0sSTc","outputId":"79873dfa-c404-4035-fe07-73e03d2b1c1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zl2GJXFqaf-a"},"outputs":[],"source":["class Preprocess_Util:\n","  #This Utility class performs EDA on the input data\n","\n","  #Constructor func\n","  def __init__(self):\n","    self.imageFilepath=\"/content/drive/MyDrive/Object_Localisation/Data_Set/images/\"\n","    self.ip_dataframe=pickle.load(open('/content/drive/MyDrive/Object_Localisation/Pickled_Data/IpDataFrame.pickle','rb'))\n","    print(\"# Shape #\")\n","    # Add a filename extension\n","    self.ip_dataframe['filename']=self.ip_dataframe['image_name'] +'.jpg'\n","    print(self.ip_dataframe.shape)\n","    print(\"##########################################################################\")\n","    #print(\"# Sample Records #\")\n","    #print(self.ip_dataframe.sample(5))\n","    #print(\"##########################################################################\")\n","    #print(\"# First 5  Records #\")\n","    #print(self.ip_dataframe.head(5))\n","    #print(\"##########################################################################\")\n","    self.rowSize=self.ip_dataframe.shape[0]\n","    #image length and width we desire\n","    self.expImageLength=256\n","    self.expImageWidth=256\n","    #Check if pickled Train tensors already exist as part of the previously executed run of the program\n","    if(os.path.isfile('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Train.npy')):\n","      self.flagFormatTrainData=False\n","    else:\n","      self.flagFormatTrainData=True\n","    #Check if pickled Test tensors already exist as part of the previously executed run of the program\n","    if(os.path.isfile('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Test.npy')):\n","      self.flagFormatTestData=False\n","    else:\n","      self.flagFormatTestData=True\n","  \n","  def splitTrainTest(self):\n","    self.train_df,self.test_df=train_test_split(self.ip_dataframe,test_size=.30,random_state=0,stratify=self.ip_dataframe['id'],shuffle=True)\n","    # Check stats on splits\n","    print(\"train_df.shape \",self.train_df.shape)\n","    print(\"##########################################################################\")\n","    print(\"test_df.shape \",self.test_df.shape)\n","    print(\"##########################################################################\")\n","    #print(\"Check label balance in Train \",(self.train_df['id'].value_counts(normalize=True)).sort_index())\n","    #print(\"##########################################################################\")\n","    #print(\"Check label balance in Test \", (self.test_df['id'].value_counts(normalize=True)).sort_index())\n","    #print(\"##########################################################################\")\n","    #Lets check if the records were shuffled well\n","    #print(\"First 5 sample records of Train\",self.train_df.head(100))\n","    #print(\"##########################################################################\")\n","    #print(\"First 5 sample records of Test \",self.test_df.head(5))\n","    #print(\"##########################################################################\")\n","    return\n","\n","\n","  def formatTrainData(self):\n","    if(self.flagFormatTrainData == True):\n","      # Convert Data to an appropraite form for modelling\n","      # Since we are going to build the model from scrach using tensor flow, we will convert data to tensors\n","      # create Image tensor\n","      X_Train=np.zeros([self.train_df.shape[0],self.expImageLength,self.expImageLength,3])\n","      # Regression Labels\n","      Y_Train_RegLabel=np.zeros([self.train_df.shape[0],4])\n","      # Classification labels\n","      Y_Train_ClassLabel=np.zeros([self.train_df.shape[0],1])\n","      # Loop over dataframe and create tensors\n","      for counter in np.arange(0,self.train_df.shape[0],1) :\n","        eachRecord=self.ip_dataframe.iloc[counter]\n","        #Get path\n","        eachImagePath=self.imageFilepath + str(eachRecord['filename'])\n","        eachIm=img.imread(eachImagePath)\n","        #Get Size\n","        eachImLength=eachIm.shape[0]\n","        eachImWidth=eachIm.shape[1]\n","        # Resize Images\n","        eachImgResized=cv2.resize(eachIm, dsize=(self.expImageLength, self.expImageWidth), interpolation=cv2.INTER_CUBIC)\n","        #Get BB box\n","        eachImgXmin=eachRecord['xmin']\n","        eachImgYmin=eachRecord['ymin']\n","        eachImgXmax=eachRecord['xmax']\n","        eachImgYmax=eachRecord['ymax']\n","        #Resize BB\n","        eachImgXmin=int(int(eachImgXmin)*self.expImageWidth/eachImWidth)\n","        eachImgXmax=int(int(eachImgXmax)*self.expImageWidth/eachImWidth)\n","        eachImgYmin=int(int(eachImgYmin)*self.expImageLength/eachImLength)\n","        eachImgYmax=int(int(eachImgYmax)*self.expImageLength/eachImLength)\n","        # Append tensors\n","        X_Train[counter]=eachImgResized\n","        Y_Train_RegLabel[counter]=[eachImgXmin,eachImgYmin,eachImgXmax,eachImgYmax]\n","        #NTS optionally can also do pd.Series(data=[eachImgXmin,eachImgYmin,eachImgXmax,eachImgYmax])\n","        Y_Train_ClassLabel[counter]=eachRecord['id']\n","\n","      #Lets check sizes of our tensors\n","      print(\"# Tensor Data #\")\n","      print('counter :',counter)\n","      print('X Image Tensor Size: ',X_Train.shape)\n","      print('Y Reg  Label Size: ',Y_Train_RegLabel.shape)\n","      print('Y Class Label Size: ',Y_Train_ClassLabel.shape)\n","      print(\"##########################################################################\")\n","      # pickle Tensor Data\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Train.npy',X_Train)\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Train_RegLabel.npy',Y_Train_RegLabel)\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Train_ClassLabel.npy',Y_Train_ClassLabel)\n","      #NTS: Pickle.dump func available on certain objects like df, for tensors , use np.save which is the same thing\n","\n","    return\n","\n","\n","  def formatTestData(self):\n","    if(self.flagFormatTestData == True):\n","      # Convert Data to an appropraite form for modelling\n","      # Since we are going to build the model from scrach using tensor flow, we will convert data to tensors\n","      # create Image tensor\n","      X_Test=np.zeros([self.test_df.shape[0],self.expImageLength,self.expImageLength,3])\n","      # Regression Labels\n","      Y_Test_RegLabel=np.zeros([self.test_df.shape[0],4])\n","      # Classification labels\n","      Y_Test_ClassLabel=np.zeros([self.test_df.shape[0],1])\n","      # Loop over dataframe and create tensors\n","      for counter in np.arange(0,self.test_df.shape[0],1) :\n","        eachRecord=self.ip_dataframe.iloc[counter]\n","        #Get path\n","        eachImagePath=self.imageFilepath + str(eachRecord['filename'])\n","        eachIm=img.imread(eachImagePath)\n","        #Get Size\n","        eachImLength=eachIm.shape[0]\n","        eachImWidth=eachIm.shape[1]\n","        # Resize Images\n","        eachImgResized=cv2.resize(eachIm, dsize=(self.expImageLength, self.expImageWidth), interpolation=cv2.INTER_CUBIC)\n","        #Get BB box\n","        eachImgXmin=eachRecord['xmin']\n","        eachImgYmin=eachRecord['ymin']\n","        eachImgXmax=eachRecord['xmax']\n","        eachImgYmax=eachRecord['ymax']\n","        #Resize BB\n","        eachImgXmin=int(int(eachImgXmin)*self.expImageWidth/eachImWidth)\n","        eachImgXmax=int(int(eachImgXmax)*self.expImageWidth/eachImWidth)\n","        eachImgYmin=int(int(eachImgYmin)*self.expImageLength/eachImLength)\n","        eachImgYmax=int(int(eachImgYmax)*self.expImageLength/eachImLength)\n","        # Append tensors\n","        X_Test[counter]=eachImgResized\n","        Y_Test_RegLabel[counter]=[eachImgXmin,eachImgYmin,eachImgXmax,eachImgYmax]\n","        #NTS optionally can also do pd.Series(data=[eachImgXmin,eachImgYmin,eachImgXmax,eachImgYmax])\n","        Y_Test_ClassLabel[counter]=eachRecord['id']\n","\n","      #Lets check sizes of our tensors\n","      print(\"# Tensor Data #\")\n","      print('counter :',counter)\n","      print('X Image Tensor Size: ',X_Test.shape)\n","      print('Y Reg  Label Size: ',Y_Test_RegLabel.shape)\n","      print('Y Class Label Size: ',Y_Test_ClassLabel.shape)\n","      print(\"##########################################################################\")\n","      # pickle Tensor Data\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Test.npy',X_Test)\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Test_RegLabel.npy',Y_Test_RegLabel)\n","      np.save('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Test_ClassLabel.npy',Y_Test_ClassLabel)\n","      #NTS: Pickle.dump func available on certain objects like df, for tensors , use np.save which is the same thing\n","\n","    return\n","\n","  def visualizeTrainImages(self,noOfImages):\n","      #Load pickled data\n","      self.X_Train=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Train.npy')\n","      self.Y_Train_RegLabel=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Train_RegLabel.npy')\n","      self.Y_Train_ClassLabel=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Train_ClassLabel.npy')\n","      \n","      #Choose #noOfImages images Randomly & Display image with bounding box and label\n","      fig = plt.figure(figsize=(15,15))\n","      for i in np.arange(0,4,1):\n","        random.seed(i)\n","        genRandNum= random.randint(0,self.train_df.shape[0])\n","        image=self.X_Train[genRandNum]\n","        #print(\"##########################################################################\")\n","        xmin=self.Y_Train_RegLabel[genRandNum][0]\n","        xmax=self.Y_Train_RegLabel[genRandNum][2]\n","        ymin=self.Y_Train_RegLabel[genRandNum][1]\n","        ymax=self.Y_Train_RegLabel[genRandNum][3]\n","        label=self.Y_Train_ClassLabel[genRandNum][0]\n","\n","        # Display Image with bb\n","        ax=plt.subplot(noOfImages/2,2,i+1)\n","        plt.grid(False)\n","        plt.imshow(image/255)\n","        rect = patches.Rectangle((int(xmin), int(ymin)), int(xmax) - int(xmin), int(ymax) - int(ymin), linewidth=2, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","        plt.title(label)\n","      return\n","\n","  def visualizeTestImages(self,noOfImages):\n","      #Load pickled data\n","      self.X_Test=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/X_Test.npy')\n","      self.Y_Test_RegLabel=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Test_RegLabel.npy')\n","      self.Y_Test_ClassLabel=np.load('/content/drive/MyDrive/Object_Localisation/Pickled_Data/Y_Test_ClassLabel.npy')\n","      \n","      #Choose #noOfImages images Randomly & Display image with bounding box and label\n","      fig = plt.figure(figsize=(15,15))\n","      for i in np.arange(0,4,1):\n","        random.seed(i)\n","        genRandNum= random.randint(0,self.test_df.shape[0])\n","        image=self.X_Test[genRandNum]\n","        #print(\"##########################################################################\")\n","        xmin=self.Y_Test_RegLabel[genRandNum][0]\n","        xmax=self.Y_Test_RegLabel[genRandNum][2]\n","        ymin=self.Y_Test_RegLabel[genRandNum][1]\n","        ymax=self.Y_Test_RegLabel[genRandNum][3]\n","        label=self.Y_Test_ClassLabel[genRandNum][0]\n","\n","        # Display Image with bb\n","        ax=plt.subplot(noOfImages/2,2,i+1)\n","        plt.grid(False)\n","        plt.imshow(image/255)\n","        rect = patches.Rectangle((int(xmin), int(ymin)), int(xmax) - int(xmin), int(ymax) - int(ymin), linewidth=2, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","        plt.title(label)\n","      return\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa8Tz5XH6zwS","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ieqwb8-8XiGj2k7m2ii7OkkxMrgF6quQ"},"executionInfo":{"status":"ok","timestamp":1675889523377,"user_tz":-330,"elapsed":775003,"user":{"displayName":"Radhika Keni","userId":"06333197448618588360"}},"outputId":"729ae01e-af32-474f-cda5-bdf39f669760"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["if __name__ == \"__main__\":\n","  objPreproc= Preprocess_Util()\n","  objPreproc.splitTrainTest()\n","  objPreproc.formatTrainData()\n","  objPreproc.formatTestData()\n","  objPreproc.visualizeTrainImages(4)\n","  objPreproc.visualizeTestImages(4)"]},{"cell_type":"markdown","metadata":{"id":"DYm0kNsogR1W"},"source":["### Inferences\n","- Data has been preprocessed into tensors and looks ready for model building\n"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}